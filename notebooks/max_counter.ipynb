{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2357fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Callable\n",
    "from ultralytics import YOLO\n",
    "from supervision import VideoInfo, VideoSink, Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89588ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../YOLOv6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c5db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolov6.data.data_augment import letterbox\n",
    "from yolov6.layers.common import DetectBackend\n",
    "from yolov6.utils.nms import non_max_suppression\n",
    "from yolov6.utils.events import load_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1705f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervision import VideoInfo, VideoSink, Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(\n",
    "    source_path: str,\n",
    "    target_path: str,\n",
    "    callback: Callable[[np.ndarray, int], np.ndarray],\n",
    "    start: int = 0,\n",
    "    end: int = 0,\n",
    "    stride: int = 1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process a video file by applying a callback function on each frame\n",
    "        and saving the result to a target video file.\n",
    "\n",
    "    Args:\n",
    "        source_path (str): The path to the source video file.\n",
    "        target_path (str): The path to the target video file.\n",
    "        callback (Callable[[np.ndarray, int], np.ndarray]): A function that takes in\n",
    "            a numpy ndarray representation of a video frame and an\n",
    "            int index of the frame and returns a processed numpy ndarray\n",
    "            representation of the frame.\n",
    "\n",
    "    Examples:\n",
    "        ```python\n",
    "        import supervision as sv\n",
    "\n",
    "        def callback(scene: np.ndarray, index: int) -> np.ndarray:\n",
    "            ...\n",
    "\n",
    "        process_video(\n",
    "            source_path='...',\n",
    "            target_path='...',\n",
    "            callback=callback\n",
    "        )\n",
    "        ```\n",
    "    \"\"\"\n",
    "    source_video_info = VideoInfo.from_video_path(video_path=source_path)\n",
    "    with VideoSink(target_path=target_path, video_info=source_video_info) as sink:\n",
    "        for index, frame in enumerate(\n",
    "            sv.get_video_frames_generator(source_path, start=start, end=end, stride=stride)\n",
    "        ):\n",
    "            result_frame = callback(frame, index)\n",
    "            sink.write_frame(frame=result_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a86f0523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(\n",
    "    source_path: str,\n",
    "    target_path: str,\n",
    "    callback: Callable[[np.ndarray, int], np.ndarray],\n",
    "    start: int = 0,\n",
    "    end: int = 0,\n",
    "    stride: int = 1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process a video file by applying a callback function on each frame\n",
    "        and saving the result to a target video file.\n",
    "\n",
    "    Args:\n",
    "        source_path (str): The path to the source video file.\n",
    "        target_path (str): The path to the target video file.\n",
    "        callback (Callable[[np.ndarray, int], np.ndarray]): A function that takes in\n",
    "            a numpy ndarray representation of a video frame and an\n",
    "            int index of the frame and returns a processed numpy ndarray\n",
    "            representation of the frame.\n",
    "\n",
    "    Examples:\n",
    "        ```python\n",
    "        import supervision as sv\n",
    "\n",
    "        def callback(scene: np.ndarray, index: int) -> np.ndarray:\n",
    "            ...\n",
    "\n",
    "        process_video(\n",
    "            source_path='...',\n",
    "            target_path='...',\n",
    "            callback=callback\n",
    "        )\n",
    "        ```\n",
    "    \"\"\"\n",
    "    source_video_info = VideoInfo.from_video_path(video_path=source_path)\n",
    "    with VideoSink(target_path=target_path, video_info=source_video_info) as sink:\n",
    "        for index, frame in enumerate(\n",
    "            sv.get_video_frames_generator(source_path, start=start, end=end, stride=stride)\n",
    "        ):\n",
    "            result_frame = callback(frame, index)\n",
    "            sink.write_frame(frame=result_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e95196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8cc968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DetectBackend('../models/yolov6s.pt', device=device)\n",
    "model = YOLO(\"yolo11s.pt\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a8119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = model.stride\n",
    "img_size = [1920, 1088]  # standard size\n",
    "half = False\n",
    "model.model.float()\n",
    "frame_stride = 2\n",
    "\n",
    "class_names = load_yaml('../datasets/coco.yaml')['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4a84fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0700dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_CLASS_NAMES = ['person', 'bicycle', 'car', 'motorcycle', 'bus', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99e0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_CLASS_IDS = [\n",
    "    {value: key for key, value in class_names.items()}[class_name]\n",
    "    for class_name\n",
    "    in SELECTED_CLASS_NAMES\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d541f855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/aula1/resized/Aula_1_192.168.5.1_20250415074041_20250415083559_500661093.mp4': [[[0, 1088], [1380, 1088]], [[1380, 1088], [1570, 380]], [[1570, 380], [1200, 215]], [[1200, 215], [1070, 205]], [[1070, 205], [500, 350]], [[500, 350], [300, 450]], [[300, 450], [0, 850]], [[0, 1088], [0, 850]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/aula2/resized/Aula_2_192.168.5.1_20250415074052_20250415083558_500637076.mp4': [[[0, 1088], [1400, 1088]], [[1400, 1088], [1550, 800]], [[1550, 800], [1470, 450]], [[1470, 450], [1350, 340]], [[1350, 340], [720, 250]], [[720, 250], [680, 280]], [[680, 280], [680, 360]], [[680, 360], [50, 700]], [[0, 1088], [50, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_A1/resized/BRAMA_A1_Rejestrator_2_20250415074006_20250415074556_502832788.mp4': [[[830, 685], [30, 900]], [[990, 600], [830, 685]], [[1920, 800], [990, 600]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_A1/resized/BRAMA_A1_Rejestrator_2_20250415074555_20250415083559_502833959.mp4': [[[830, 685], [30, 900]], [[990, 600], [830, 685]], [[1920, 800], [990, 600]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250415075242_20250415083558_501699183.mp4': [[[1010, 230], [0, 800]], [[1500, 200], [1010, 230]], [[1800, 260], [500, 1088]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250415074005_20250415075242_501697548.mp4': [[[1010, 230], [0, 800]], [[1500, 200], [1010, 230]], [[1800, 260], [500, 1088]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_Niepodleglosci/resized/BRAMA_NIEPODLEGLOSCI_192.168.5.149_20250415073956_20250415081246_501548858.mp4': [[[1150, 220], [560, 360]], [[1570, 250], [100, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_Niepodleglosci/resized/BRAMA_NIEPODLEGLOSCI_192.168.5.149_20250415081246_20250415083559_501556429.mp4': [[[1150, 220], [560, 360]], [[1570, 250], [100, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_Nowowiejska/resized/Brama_Nowowiejska_Rejestrator_2_20250415074000_20250415083559_503175768.mp4': [[[825, 305], [350, 420]], [[1125, 320], [825, 305]], [[1700, 300], [0, 950]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Plac/resized/PLAC_192.168.5.1_20250415074053_20250415083558_500649183.mp4': [[[1760, 300], [350, 150]], [[0, 1088], [1550, 1088]], [[0, 220], [0, 1088]], [[350, 150], [0, 220]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/aula1/resized/Aula_1_192.168.5.1_20250415114001_20250415115624_517982300.mp4': [[[0, 1088], [1380, 1088]], [[1380, 1088], [1570, 380]], [[1570, 380], [1200, 215]], [[1200, 215], [1070, 205]], [[1070, 205], [500, 350]], [[500, 350], [300, 450]], [[300, 450], [0, 850]], [[0, 1088], [0, 850]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/aula1/resized/Aula_1_192.168.5.1_20250415115624_20250415124035_517984012.mp4': [[[0, 1088], [1380, 1088]], [[1380, 1088], [1570, 380]], [[1570, 380], [1200, 215]], [[1200, 215], [1070, 205]], [[1070, 205], [500, 350]], [[500, 350], [300, 450]], [[300, 450], [0, 850]], [[0, 1088], [0, 850]], [[0, 1088], [50, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/aula2/resized/Aula_2_192.168.5.1_20250415114012_20250415124034_517994518.mp4': [[[0, 1088], [1400, 1088]], [[1400, 1088], [1550, 800]], [[1550, 800], [1470, 450]], [[1470, 450], [1350, 340]], [[1350, 340], [720, 250]], [[720, 250], [680, 280]], [[680, 280], [680, 360]], [[680, 360], [50, 700]], [[0, 1088], [50, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/Br_A1/resized/BRAMA_A1_Rejestrator_2_20250415114011_20250415123535_519614037.mp4': [[[830, 685], [30, 900]], [[990, 600], [830, 685]], [[1920, 800], [990, 600]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250415114001_20250415123535_519148799.mp4': [[[1010, 230], [0, 800]], [[1500, 200], [1010, 230]], [[1800, 260], [500, 1088]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/Br_Niepodleglosci/resized/BRAMA_NIEPODLEGLOSCI_192.168.5.149_20250415113958_20250415123534_519198311.mp4': [[[1150, 220], [560, 360]], [[1570, 250], [100, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/Br_Nowowiejska/resized/Brama_Nowowiejska_Rejestrator_2_20250415114002_20250415115541_519629363.mp4': [[[825, 305], [350, 420]], [[1125, 320], [825, 305]], [[1700, 300], [0, 950]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/Br_Nowowiejska/resized/Brama_Nowowiejska_Rejestrator_2_20250415115541_20250415123534_519632340.mp4': [[[825, 305], [350, 420]], [[1125, 320], [825, 305]], [[1700, 300], [0, 950]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/Plac/resized/PLAC_192.168.5.1_20250415120616_20250415124035_518024578.mp4': [[[1760, 300], [350, 150]], [[0, 1088], [1550, 1088]], [[0, 220], [0, 1088]], [[350, 150], [0, 220]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/11-12/Plac/resized/PLAC_192.168.5.1_20250415114014_20250415120616_518019648.mp4': [[[1760, 300], [350, 150]], [[0, 1088], [1550, 1088]], [[0, 220], [0, 1088]], [[350, 150], [0, 220]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/7-8/aula1/resized/Aula_1_192.168.5.1_20250416074008_20250416083533_627866924.mp4': [[[0, 1088], [1380, 1088]], [[1380, 1088], [1570, 380]], [[1570, 380], [1200, 215]], [[1200, 215], [1070, 205]], [[1070, 205], [500, 350]], [[500, 350], [300, 450]], [[300, 450], [0, 850]], [[0, 1088], [0, 850]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/7-8/aula2/resized/Aula_2_192.168.5.1_20250416074032_20250416083534_627880543.mp4': [[[0, 1088], [1400, 1088]], [[1400, 1088], [1550, 800]], [[1550, 800], [1470, 450]], [[1470, 450], [1350, 340]], [[1350, 340], [720, 250]], [[720, 250], [680, 280]], [[680, 280], [680, 360]], [[680, 360], [50, 700]], [[0, 1088], [50, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/7-8/Br_A1/resized/BRAMA_A1_Rejestrator_2_20250416073951_20250416083535_628845734.mp4': [[[830, 685], [30, 900]], [[990, 600], [830, 685]], [[1920, 800], [990, 600]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/7-8/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250416073954_20250416082233_628427961.mp4': [[[1010, 230], [0, 800]], [[1500, 200], [1010, 230]], [[1800, 260], [500, 1088]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/7-8/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250416082233_20250416083535_628433746.mp4': [[[1010, 230], [0, 800]], [[1500, 200], [1010, 230]], [[1800, 260], [500, 1088]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/7-8/Br_Niepodleglosci/resized/BRAMA_NIEPODLEGLOSCI_192.168.5.149_20250416073959_20250416081709_628448257.mp4': [[[1150, 220], [560, 360]], [[1570, 250], [100, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/7-8/Br_Niepodleglosci/resized/BRAMA_NIEPODLEGLOSCI_192.168.5.149_20250416081709_20250416083534_628456853.mp4': [[[1150, 220], [560, 360]], [[1570, 250], [100, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/7-8/Br_Nowowiejska/resized/Brama_Nowowiejska_Rejestrator_2_20250416074018_20250416083534_628860471.mp4': [[[825, 305], [350, 420]], [[1125, 320], [825, 305]], [[1700, 300], [0, 950]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/7-8/Plac/resized/PLAC_192.168.5.1_20250416074022_20250416083534_627892248.mp4': [[[1760, 300], [350, 150]], [[0, 1088], [1550, 1088]], [[0, 220], [0, 1088]], [[350, 150], [0, 220]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/11-12/aula1/resized/Aula_1_192.168.5.1_20250416114000_20250416123534_629196533.mp4': [[[0, 1088], [1380, 1088]], [[1380, 1088], [1570, 380]], [[1570, 380], [1200, 215]], [[1200, 215], [1070, 205]], [[1070, 205], [500, 350]], [[500, 350], [300, 450]], [[300, 450], [0, 850]], [[0, 1088], [0, 850]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/11-12/aula2/resized/Aula_2_192.168.5.1_20250416114022_20250416123534_629207389_(1).mp4': [[[0, 1088], [1400, 1088]], [[1400, 1088], [1550, 800]], [[1550, 800], [1470, 450]], [[1470, 450], [1350, 340]], [[1350, 340], [720, 250]], [[720, 250], [680, 280]], [[680, 280], [680, 360]], [[680, 360], [50, 700]], [[0, 1088], [50, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/11-12/Br_A1/resized/BRAMA_A1_Rejestrator_2_20250416122645_20250416123534_630333234.mp4': [[[830, 685], [30, 900]], [[990, 600], [830, 685]], [[1920, 800], [990, 600]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/11-12/Br_A1/resized/BRAMA_A1_Rejestrator_2_20250416114010_20250416122645_630323787.mp4': [[[830, 685], [30, 900]], [[990, 600], [830, 685]], [[1920, 800], [990, 600]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/11-12/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250416114556_20250416123535_629951582.mp4': [[[1010, 230], [0, 800]], [[1500, 200], [1010, 230]], [[1800, 260], [500, 1088]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/11-12/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250416113957_20250416114555_629950393.mp4': [[[1010, 230], [0, 800]], [[1500, 200], [1010, 230]], [[1800, 260], [500, 1088]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/11-12/Br_Niepodleglosci/resized/BRAMA_NIEPODLEGLOSCI_192.168.5.149_20250416114003_20250416123533_629967206.mp4': [[[1150, 220], [560, 360]], [[1570, 250], [100, 700]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/11-12/Br_Nowowiejska/resized/Brama_Nowowiejska_Rejestrator_2_20250416114001_20250416123535_630091638.mp4': [[[825, 305], [350, 420]], [[1125, 320], [825, 305]], [[1125, 320], [825, 305]]], '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/16_04_25/11-12/Plac/resized/PLAC_192.168.5.1_20250416114027_20250416123534_629224297.mp4': [[[1760, 300], [350, 150]], [[0, 1088], [1550, 1088]], [[0, 220], [0, 1088]], [[350, 150], [0, 220]]]}\n"
     ]
    }
   ],
   "source": [
    "with open('../src/coords.json') as f:\n",
    "    coords = json.load(f)\n",
    "    print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8986135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    image = letterbox(frame, img_size, stride=stride)[0]\n",
    "    image = image.transpose((2, 0, 1))[::-1].copy()  # BGR to RGB, HWC to CHW\n",
    "    image = torch.from_numpy(image).float() / 255.0\n",
    "    image = image.unsqueeze(0)  # add batch dimension\n",
    "    \n",
    "    if half:\n",
    "        image = image.half()\n",
    "    \n",
    "    image = image.to(device)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb5bf04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, frame):\n",
    "    with torch.no_grad():\n",
    "        pred = model(frame)\n",
    "        det = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45,classes=[0])[0]\n",
    "    \n",
    "    xyxy = det[:, :4].cpu().numpy().astype('float32')\n",
    "    confidence = det[:, 4].cpu().numpy().astype('float32')\n",
    "    class_id = det[:, 5].cpu().numpy().astype(int)\n",
    "    mask = None\n",
    "    tracker_id = None\n",
    "\n",
    "    return (xyxy, confidence, class_id, mask, tracker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6823ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detections(xyxy, confidence, class_id, mask, tracker_id):\n",
    "    return Detections(\n",
    "        xyxy=xyxy,\n",
    "        confidence=confidence,\n",
    "        class_id=class_id,\n",
    "        mask=None,\n",
    "        tracker_id=tracker_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98aa6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_in_out_window(frame: np.ndarray, in_counts: dict, out_counts: dict) -> np.ndarray:\n",
    "    x, y = frame.shape[1] - 300, 30\n",
    "    width, height = 270, 160\n",
    "    overlay = frame.copy()\n",
    "\n",
    "    # Semi-transparent background\n",
    "    cv2.rectangle(overlay, (x, y), (x + width, y + height), (255, 255, 255), -1)\n",
    "    alpha = 0.6\n",
    "    frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "\n",
    "    # Draw text\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.6\n",
    "    font_color = (0, 0, 0)\n",
    "    line_height = 25\n",
    "    offset_y = y + 25\n",
    "\n",
    "    for class_name in SELECTED_CLASS_NAMES:\n",
    "        class_id = [k for k, v in class_names.items() if v == class_name]\n",
    "        in_count = in_counts[class_id[0]] if class_id else 0\n",
    "        out_count = out_counts[class_id[0]] if class_id else 0\n",
    "        cv2.putText(frame, f\"{class_name} In: {in_count}  Out: {out_count}\",\n",
    "                    (x + 10, offset_y), font, font_scale, font_color, 2)\n",
    "        offset_y += line_height\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f12ebfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video info: VideoInfo(width=1920, height=1088, fps=14, total_frames=11344)\n",
      "Processing /Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250415074005_20250415075242_501697548.mp4 -> /Users/grzegorzsmereczniak/Documents/MyPW/results/monitoring_pw/15_04_25/7-8/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250415074005_20250415075242_501697548.mp4\n",
      "Lines coords: [(Point(x=1010, y=230), Point(x=0, y=800)), (Point(x=1500, y=200), Point(x=1010, y=230)), (Point(x=1800, y=260), Point(x=500, y=1088))]\n",
      "Processed /Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250415074005_20250415075242_501697548.mp4 in 236.78 seconds\n"
     ]
    }
   ],
   "source": [
    "for source_path, coords_list in coords.items():\n",
    "    if source_path == '/Users/grzegorzsmereczniak/Documents/MyPW/data/monitoring_pw/15_04_25/7-8/Br_Koszykowa/resized/Brama_Koszykowa_192.168.5.149_20250415074005_20250415075242_501697548.mp4':\n",
    "        video_info = sv.VideoInfo.from_video_path(source_path)\n",
    "        print(f'Video info: {video_info}')\n",
    "        target_path = source_path.replace('data', 'results')\n",
    "        line_coords = []\n",
    "        line_zones = []\n",
    "        total_in = defaultdict(int)\n",
    "        total_out = defaultdict(int)\n",
    "\n",
    "        print(f'Processing {source_path} -> {target_path}')\n",
    "        for cs in coords_list:\n",
    "            line_coords.append((sv.Point(*cs[0]), sv.Point(*cs[1])))\n",
    "\n",
    "        print(f'Lines coords: {line_coords}')\n",
    "\n",
    "        for line_coord in line_coords:\n",
    "            line_zones.append(sv.LineZone(start=line_coord[0], end=line_coord[1]))\n",
    "\n",
    "        \n",
    "        zone_class_counts = [\n",
    "            {\"in\": defaultdict(int), \"out\": defaultdict(int)}\n",
    "            for _ in line_zones\n",
    "        ]\n",
    "\n",
    "        # create instance of BoxAnnotator, LabelAnnotator, and TraceAnnotator\n",
    "        box_annotator = sv.BoxAnnotator(thickness=4)\n",
    "        label_annotator = sv.LabelAnnotator(text_thickness=2, text_scale=1.5, text_color=sv.Color.BLACK)\n",
    "        trace_annotator = sv.TraceAnnotator(thickness=4, trace_length=50)\n",
    "\n",
    "        # create LineZoneAnnotator instance\n",
    "        line_zone_annotators = [\n",
    "            sv.LineZoneAnnotator(thickness=4, text_thickness=4, text_scale=0, text_orient_to_line=True)\n",
    "            for _ in line_zones\n",
    "        ]\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # create BYTETracker instance\n",
    "        byte_tracker = sv.ByteTrack(\n",
    "            track_activation_threshold=0.25,\n",
    "            lost_track_buffer=30,\n",
    "            minimum_matching_threshold=0.8,\n",
    "            frame_rate=video_info.fps,\n",
    "            minimum_consecutive_frames=3)\n",
    "\n",
    "        byte_tracker.reset()\n",
    "\n",
    "        # def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
    "        #     detections = get_detections(*get_results(model, process_frame(frame)))\n",
    "        #     detections = detections[np.isin(detections.class_id, SELECTED_CLASS_IDS)]\n",
    "        #     detections = byte_tracker.update_with_detections(detections)\n",
    "\n",
    "        #     labels = [\n",
    "        #         f\"#{tracker_id} {class_names[class_id]} {confidence:0.2f}\"\n",
    "        #         for confidence, class_id, tracker_id\n",
    "        #         in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
    "        #     ]\n",
    "\n",
    "        #     annotated_frame = frame.copy()\n",
    "        #     annotated_frame = trace_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "        #     annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "        #     annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "        #     # === Dla każdej linii wykonaj trigger + annotate\n",
    "        #     for zone, annotator in zip(line_zones, line_zone_annotators):\n",
    "        #         zone.trigger(detections)\n",
    "        #         annotated_frame = annotator.annotate(annotated_frame, line_counter=zone)\n",
    "\n",
    "        #     return annotated_frame\n",
    "        \n",
    "        def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
    "            results = model(frame, conf=0.1, verbose=False)[0]\n",
    "            detections = sv.Detections.from_ultralytics(results)\n",
    "            detections = detections[np.isin(detections.class_id, SELECTED_CLASS_IDS)]\n",
    "            detections = byte_tracker.update_with_detections(detections)\n",
    "\n",
    "            labels = [\n",
    "                f\"#{tracker_id} {class_names[class_id]} {confidence:0.2f}\"\n",
    "                for confidence, class_id, tracker_id\n",
    "                in zip(detections.confidence, detections.class_id, detections.tracker_id)\n",
    "            ]\n",
    "\n",
    "            annotated_frame = frame.copy()\n",
    "            annotated_frame = trace_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "            annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "            annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "            # === Dla każdej linii wykonaj trigger + annotate\n",
    "            for i, (zone, annotator) in enumerate(zip(line_zones, line_zone_annotators)):\n",
    "                crossed_in, crossed_out = zone.trigger(detections)\n",
    "                annotated_frame = annotator.annotate(annotated_frame, line_counter=zone)\n",
    "\n",
    "                for class_id, is_in in zip(detections.class_id, crossed_in):\n",
    "                    if is_in:\n",
    "                        zone_class_counts[i][\"in\"][class_id] += 1\n",
    "\n",
    "                for class_id, is_out in zip(detections.class_id, crossed_out):\n",
    "                    if is_out:\n",
    "                        zone_class_counts[i][\"out\"][class_id] += 1\n",
    "\n",
    "            # compute max across zones\n",
    "            max_in = defaultdict(int)\n",
    "            max_out = defaultdict(int)\n",
    "\n",
    "            for zone_counts in zone_class_counts:\n",
    "                for class_id, count in zone_counts[\"in\"].items():\n",
    "                    max_in[class_id] = max(max_in[class_id], count)\n",
    "                for class_id, count in zone_counts[\"out\"].items():\n",
    "                    max_out[class_id] = max(max_out[class_id], count)\n",
    "\n",
    "            annotated_frame = draw_in_out_window(annotated_frame, max_in, max_out)\n",
    "\n",
    "            return annotated_frame\n",
    "\n",
    "        \n",
    "        process_video(\n",
    "            source_path = source_path,\n",
    "            target_path = target_path,\n",
    "            callback=callback,\n",
    "            start=0,\n",
    "            end=None,\n",
    "            stride=2\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f\"Processed {source_path} in {elapsed_time:.2f} seconds\")\n",
    "        break\n",
    "\n",
    "        # generator = sv.get_video_frames_generator(source_path, stride=stride)\n",
    "\n",
    "        # box_annotator = sv.BoxAnnotator(thickness=4)\n",
    "        # label_annotator = sv.LabelAnnotator(text_thickness=2, text_scale=1.5, text_color=sv.Color.BLACK)\n",
    "\n",
    "        # iterator = iter(generator)\n",
    "        # frame = next(iterator)\n",
    "        # processed_frame = process_frame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88fe0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov6_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
